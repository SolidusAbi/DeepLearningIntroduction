{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import simulations.simpleImages as simulation\n",
    "import simulations.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "M = 128\n",
    "input_images, target_masks = simulation.generate_random_data(M, M, count=N)\n",
    "\n",
    "n_samples, x_size, y_size, n_channels = input_images.shape\n",
    "n_samples, n_masks, x_size, y_size = target_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_images.shape)\n",
    "print(target_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input_images**: (1, M, M, C) -> 1 imagen de MxM con C canales\n",
    "\n",
    "**target_masks**: (1, N, M, M) -> 1 imagen con N mascaras de imagenes de MxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change channel-order and make 3 channels for matplot \n",
    "input_images_rgb = list(input_images.astype(np.uint8))\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [utils.masks_to_colorimg(x) for x in target_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.show_images_samples(input_images_rgb, target_masks_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from simulations.simpleImages import generate_random_data\n",
    "\n",
    "'''\n",
    "    This module contains pytorch dataset classes that generates \n",
    "    simulations data.\n",
    "'''\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    '''\n",
    "        Pytorch Dataset of random synthetic simple images. This dataset contains simple \n",
    "        images with six figures (filled square, mesh square, circle, triangle...).\n",
    "\n",
    "        Important: \n",
    "            dataset contains (H x W x C) in the range [0, 255], if you want to \n",
    "            use it like a tensor you have to convert the shape to C x H x W) in the range [0.0, 1.0].\n",
    "\n",
    "            The easiest way is to apply torchvision.transform.ToTensor() indicating it in the initializer.\n",
    "            Ej. SimDataset(X, tranform='torchvision.transform.ToTensor()')\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = generate_random_data(192, 192, count=count)        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as torchTransforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trans = torchTransforms.Compose([\n",
    "            torchTransforms.ToTensor(),\n",
    "            torchTransforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "train_set = SimDataset(1200, transform=trans)\n",
    "val_set = SimDataset(120, transform=trans)\n",
    "\n",
    "image_datasets = { 'train' : train_set, 'val' : val_set }\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "print('Dataset Size: {}'.format(dataset_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetEncode(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        )\n",
    "\n",
    "        self._result = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._result = self.encode(x)\n",
    "        return self._result\n",
    "\n",
    "    def getResult(self):\n",
    "        return self._result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDecode(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample=True, kaiming_initialization=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, output_channels, input_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        #TODO!!\n",
    "        self.encode_lvl_0 = UNetEncode(input_channels, 64)\n",
    "        self.encode_lvl_1 = UNetEncode(64, 128)\n",
    "        self.encode_lvl_2 = UNetEncode(128, 256)\n",
    "        self.encode_lvl_3 = UNetEncode(256, 512)\n",
    "        self.encode_lvl_4 = UNetEncode(512, 1024)\n",
    "\n",
    "        self.decode_lvl_4 = UNetDecode(1024, 1024) #Bottleneck\n",
    "        self.decode_lvl_3 = UNetDecode(512 + 1024, 512)\n",
    "        self.decode_lvl_2 = UNetDecode(256 + 512, 256)\n",
    "        self.decode_lvl_1 = UNetDecode(128 + 256, 128)\n",
    "        self.decode_lvl_0 = UNetDecode(64 + 128, 64)\n",
    "        \n",
    "        self.output = nn.Conv2d(64, output_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        x = self.encode_lvl_0(x)\n",
    "        x = self.encode_lvl_1(x)\n",
    "        x = self.encode_lvl_2(x)\n",
    "        x = self.encode_lvl_3(x)\n",
    "        x = self.encode_lvl_4(x)\n",
    "\n",
    "        # Decode\n",
    "        x = self.decode_lvl_4(x)\n",
    "        x = torch.cat([x, self.encode_lvl_3.getResult()], dim=1)\n",
    "        x = self.decode_lvl_3(x)\n",
    "        x = torch.cat([x, self.encode_lvl_2.getResult()], dim=1)\n",
    "        x = self.decode_lvl_2(x)\n",
    "        x = torch.cat([x, self.encode_lvl_1.getResult()], dim=1)\n",
    "        x = self.decode_lvl_1(x)\n",
    "        x = torch.cat([x, self.encode_lvl_0.getResult()], dim=1)\n",
    "        x = self.decode_lvl_0(x)\n",
    "        \n",
    "        # Output\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "model = UNet(n_classes, 3)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function (DICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "    \n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "Prepare a test dataset just for show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "def masks_to_colorimg(masks):\n",
    "    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
    "\n",
    "    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n",
    "    channels, height, width = masks.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            selected_colors = colors[masks[:,y,x] > 0.5]\n",
    "\n",
    "            if len(selected_colors) > 0:\n",
    "                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n",
    "\n",
    "    return colorimg.astype(np.uint8)\n",
    "\n",
    "class NormalizeInverse(transforms.Normalize):\n",
    "    \"\"\"\n",
    "    This class is a inmutable implementation that undoes the normalization and \n",
    "    returns the reconstructed images in the input domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        mean = torch.as_tensor(mean)\n",
    "        std = torch.as_tensor(std)\n",
    "        std_inv = 1 / (std + 1e-10)\n",
    "        mean_inv = -mean * std_inv\n",
    "        super().__init__(mean=mean_inv, std=std_inv)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return super().__call__(tensor.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = SimDataset(6, transform=trans)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        pred = model(inputs)\n",
    "        #pred = pred.detach() #Unnecessary inside torch.no_grad() block\n",
    "        batch_predictions.append(pred.cpu())\n",
    "        \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "inv_trans = torchTransforms.Compose([\n",
    "    NormalizeInverse(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]), \n",
    "    torchTransforms.ToPILImage()\n",
    "])\n",
    "\n",
    "batch_idx = randint(0, len(batch_predictions)-1)\n",
    "example_idx = randint(0, batch_size-1)\n",
    "\n",
    "#Remember to comeback the tensor to CPU\n",
    "example = batch_predictions[batch_idx][example_idx].to('cpu')\n",
    "inputs, masks = test_set[batch_idx*batch_size + example_idx]\n",
    "\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = batch_predictions[batch_idx]\n",
    "pred = torch.sigmoid(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 30]\n",
    "from simulations import utils\n",
    "\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [masks_to_colorimg(x) for x in pred.cpu().detach().numpy()]\n",
    "\n",
    "nSamples = len(input_images_rgb)\n",
    "images = [None]*(3*nSamples)\n",
    "images[::3] = input_images_rgb\n",
    "images[1::3] = target_masks_rgb\n",
    "images[2::3] = pred_rgb\n",
    "\n",
    "utils.show_images(images, nRow=nSamples, nCol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
