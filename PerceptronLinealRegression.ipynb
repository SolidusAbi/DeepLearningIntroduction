{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dummy dataset. In this test we are going to make the perceptron infer the function f (x) = 2x + 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.arange(15, dtype=np.float32)\n",
    "y_train = 2*x_train+10\n",
    "\n",
    "x_validation = np.arange(18, 34, 2, dtype=np.float32)\n",
    "y_validation = 2*x_validation+10\n",
    "\n",
    "x_test = np.arange(50, 55, dtype=np.float32)\n",
    "y_test = 2*x_test+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(60), 2*np.arange(60)+10, color='red')\n",
    "plt.scatter(x_train, y_train, label='Training set')\n",
    "plt.scatter(x_validation, y_validation, color=\"green\", label='Validation set')\n",
    "plt.scatter(x_test, y_test, color=\"green\", label='Test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataset is divided into three variables**:\n",
    "\n",
    "**x_train:** training dataset; **y_train:** training targets;\n",
    "\n",
    "**x_validation:** validation dataset; **y_validation:** targets of validation;\n",
    "\n",
    "**x_test:** testing dataset; **y_test:** targets from test; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos ruidosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 1.2 # mean and standard deviation\n",
    "gauss_noise = np.array(np.random.normal(mu, sigma, x_train.size), dtype=np.float32).reshape(x_train.shape)\n",
    "y_train_noisy = y_train + gauss_noise\n",
    "\n",
    "plt.scatter(x_train, y_train_noisy)\n",
    "plt.plot(x_train, y_train, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y_train_noisy** contains the training *targets* by applying a Gaussian noise to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparaci√≥n del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'train': [x_train, y_train], \n",
    "           'validation': [x_validation, y_validation], \n",
    "           'test': [x_test, y_test]}\n",
    "\n",
    "dataset_noisy = {'train': [x_train, y_train_noisy], \n",
    "                 'validation': [x_validation, y_validation], \n",
    "                 'test': [x_test, y_test]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of the Perceptron and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size, bias=True)\n",
    "        self.activation = torch.nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        result = self.linear(x)\n",
    "        return self.activation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def npToTensor(x):\n",
    "    return torch.tensor(x.reshape(-1, 1))\n",
    "\n",
    "def train(dataset, model, optimizer, criterion, num_epochs=25):\n",
    "    best_model_weigths = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available:\n",
    "        device=torch.device(\"cuda\")  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'validation']:\n",
    "            inputs = npToTensor(dataset[phase][0]).to(device)\n",
    "            targets = npToTensor(dataset[phase][1]).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            if (phase == 'train'):\n",
    "                # get gradients w.r.t to parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                # LOG\n",
    "                if (epoch % 50 == 0):\n",
    "                    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "                    \n",
    "                if (loss.item() < best_loss):\n",
    "                    #print('\\tepoch {}, validation loss {}'.format(epoch, loss.item()))\n",
    "                    best_loss = loss.item()\n",
    "                    best_model_weigths = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    print('Best loss: {}'.format(best_loss))\n",
    "            \n",
    "    model.load_state_dict(best_model_weigths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our perceptron... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1        # takes variable 'x' \n",
    "output_dim = 1       # takes variable 'y'\n",
    "\n",
    "device=torch.device(\"cpu\")\n",
    "if torch.cuda.is_available:\n",
    "    device=torch.device(\"cuda\")\n",
    "\n",
    "model = Perceptron(input_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learningRate = 0.001\n",
    "epochs = 10000\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "train(dataset, model, optimizer, criterion, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = npToTensor(dataset['test'][0]).to(device)\n",
    "result = model(inputs).cpu().detach().numpy()\n",
    "\n",
    "plt.scatter(dataset['test'][0], dataset['test'][1])\n",
    "plt.plot(dataset['test'][0], result, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba con el dataset ruidoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noisy = Perceptron(input_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001\n",
    "epochs = 1000\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model_noisy.parameters(), lr=learningRate)\n",
    "\n",
    "train(dataset_noisy, model_noisy, optimizer, criterion, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = npToTensor(dataset['test'][0]).to(device)\n",
    "result = model_noisy(inputs).cpu().detach().numpy()\n",
    "\n",
    "plt.scatter(dataset['test'][0], dataset['test'][1])\n",
    "plt.plot(dataset['test'][0], result, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulo Dataset en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch import tensor\n",
    "\n",
    "class LinearDataset(Dataset):\n",
    "    '''\n",
    "        Dataset f(x)=2x+10\n",
    "    '''\n",
    "    def __init__(self, start, input_size=12, step=1, noise=False):\n",
    "        self.noise = noise\n",
    "        self.mu, self.sigma = 0, 0.5 # mean and standard deviation\n",
    "        self.x_values = np.arange(start, start + input_size*step, step, dtype=np.float32).reshape(-1,1)\n",
    "        self.gauss_noise = np.array(np.random.normal(self.mu, self.sigma, self.x_values.size), dtype=np.float32).reshape(self.x_values.shape)\n",
    "           \n",
    "    def __len__(self):\n",
    "        return self.x_values.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_values[idx]\n",
    "        y = (2*x + 10)\n",
    "        \n",
    "        if (self.noise):\n",
    "            apply = np.random.uniform() > 0.75\n",
    "            y = y + apply*self.gauss_noise[idx]\n",
    "            \n",
    "        return [tensor(x), tensor(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = LinearDataset(0, 50, 1, True)\n",
    "validation_set = LinearDataset(30, 8, 2)\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'validation': DataLoader(validation_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "}\n",
    "\n",
    "for inputs, labels in dataloaders['train']:\n",
    "    print(inputs.size())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(dataloaders, model, optimizer, criterion, num_epochs=25):\n",
    "    best_model_weigths = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available:\n",
    "        device=torch.device(\"cuda\")  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'validation']:\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                if (phase == 'train'):\n",
    "                    # get gradients w.r.t to parameters\n",
    "                    loss.backward()\n",
    "\n",
    "                    # update parameters\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    # LOG\n",
    "                    if (epoch % 50 == 0):\n",
    "                        print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "\n",
    "                    if (loss.item() < best_loss):\n",
    "                        #print('\\tepoch {}, validation loss {}'.format(epoch, loss.item()))\n",
    "                        best_loss = loss.item()\n",
    "                        best_model_weigths = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "    print('Best loss: {}'.format(best_loss))\n",
    "            \n",
    "    model.load_state_dict(best_model_weigths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = Perceptron(input_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001\n",
    "epochs = 1000\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(another_model.parameters(), lr=learningRate)\n",
    "\n",
    "train2(dataloaders, another_model, optimizer, criterion, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = npToTensor(dataset['test'][0]).to(device)\n",
    "result = another_model(inputs).cpu().detach().numpy()\n",
    "\n",
    "plt.scatter(dataset['test'][0], dataset['test'][1])\n",
    "plt.plot(dataset['test'][0], result, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
